{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 48: Predicting Avocade Price Using Neural Networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18249 entries, 0 to 18248\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    18249 non-null  int64  \n",
      " 1   Date          18249 non-null  object \n",
      " 2   AveragePrice  18249 non-null  float64\n",
      " 3   Total Volume  18249 non-null  float64\n",
      " 4   4046          18249 non-null  float64\n",
      " 5   4225          18249 non-null  float64\n",
      " 6   4770          18249 non-null  float64\n",
      " 7   Total Bags    18249 non-null  float64\n",
      " 8   Small Bags    18249 non-null  float64\n",
      " 9   Large Bags    18249 non-null  float64\n",
      " 10  XLarge Bags   18249 non-null  float64\n",
      " 11  type          18249 non-null  object \n",
      " 12  year          18249 non-null  int64  \n",
      " 13  region        18249 non-null  object \n",
      "dtypes: float64(9), int64(2), object(3)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "data = pd.read_csv('data/avocado.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data column into days and months\n",
    "data['Day'], data['Month'] = data.Date.str[:2], data.Date.str[3:5]\n",
    "#drop date and unnamed\n",
    "data = data.drop(['Unnamed: 0', 'Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use LabelEncoder for categorical variables \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from collections import defaultdict \n",
    "\n",
    "#Create label dictionary \n",
    "label_dict = defaultdict(LabelEncoder)\n",
    "\n",
    "data[['region', 'type', 'Day', 'Month', 'year']] = data[['region', 'type', 'Day', 'Month', 'year']]\\\n",
    "                                                   .apply(lambda x: label_dict[x.name].fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data \n",
    "y = X.pop('AveragePrice')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use callbacks to save the model whenever the loss improves and for early stoppping of the model \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping \n",
    "\n",
    "filepath = 'Models/avocado-{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "\n",
    "model_ckpt = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=1, patience=50, verbose=1)\n",
    "\n",
    "callbacks = [model_ckpt, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=16, activation='relu', input_dim=13))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "350/400 [=========================>....] - ETA: 0s - loss: 15954251776.0000\n",
      "Epoch 00001: val_loss improved from inf to 96683760.00000, saving model to Models/avocado-01-96683760.00.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 13998217216.0000 - val_loss: 96683760.0000\n",
      "Epoch 2/1000\n",
      "397/400 [============================>.] - ETA: 0s - loss: 62163376.0000\n",
      "Epoch 00002: val_loss improved from 96683760.00000 to 32917598.00000, saving model to Models/avocado-02-32917598.00.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 61860688.0000 - val_loss: 32917598.0000\n",
      "Epoch 3/1000\n",
      "334/400 [========================>.....] - ETA: 0s - loss: 23715368.0000\n",
      "Epoch 00003: val_loss improved from 32917598.00000 to 17382458.00000, saving model to Models/avocado-03-17382458.00.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 22542842.0000 - val_loss: 17382458.0000\n",
      "Epoch 4/1000\n",
      "341/400 [========================>.....] - ETA: 0s - loss: 12932757.0000\n",
      "Epoch 00004: val_loss improved from 17382458.00000 to 11247030.00000, saving model to Models/avocado-04-11247030.00.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 11965252.0000 - val_loss: 11247030.0000\n",
      "Epoch 5/1000\n",
      "339/400 [========================>.....] - ETA: 0s - loss: 8348099.0000\n",
      "Epoch 00005: val_loss improved from 11247030.00000 to 7799512.50000, saving model to Models/avocado-05-7799512.50.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 7846459.5000 - val_loss: 7799512.5000\n",
      "Epoch 6/1000\n",
      "355/400 [=========================>....] - ETA: 0s - loss: 5576243.5000\n",
      "Epoch 00006: val_loss improved from 7799512.50000 to 5672617.50000, saving model to Models/avocado-06-5672617.50.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 5434926.5000 - val_loss: 5672617.5000\n",
      "Epoch 7/1000\n",
      "348/400 [=========================>....] - ETA: 0s - loss: 3912975.0000\n",
      "Epoch 00007: val_loss improved from 5672617.50000 to 4250729.50000, saving model to Models/avocado-07-4250729.50.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 3831865.5000 - val_loss: 4250729.5000\n",
      "Epoch 8/1000\n",
      "338/400 [========================>.....] - ETA: 0s - loss: 3016558.0000\n",
      "Epoch 00008: val_loss improved from 4250729.50000 to 3252420.50000, saving model to Models/avocado-08-3252420.50.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 2739719.2500 - val_loss: 3252420.5000\n",
      "Epoch 9/1000\n",
      "344/400 [========================>.....] - ETA: 0s - loss: 1853683.5000\n",
      "Epoch 00009: val_loss improved from 3252420.50000 to 2458867.25000, saving model to Models/avocado-09-2458867.25.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1997484.7500 - val_loss: 2458867.2500\n",
      "Epoch 10/1000\n",
      "341/400 [========================>.....] - ETA: 0s - loss: 1460492.5000\n",
      "Epoch 00010: val_loss improved from 2458867.25000 to 1805599.12500, saving model to Models/avocado-10-1805599.12.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1420192.8750 - val_loss: 1805599.1250\n",
      "Epoch 11/1000\n",
      "353/400 [=========================>....] - ETA: 0s - loss: 1012163.2500\n",
      "Epoch 00011: val_loss improved from 1805599.12500 to 1326767.00000, saving model to Models/avocado-11-1326767.00.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 981576.1250 - val_loss: 1326767.0000\n",
      "Epoch 12/1000\n",
      "344/400 [========================>.....] - ETA: 0s - loss: 673660.8750\n",
      "Epoch 00012: val_loss improved from 1326767.00000 to 967204.56250, saving model to Models/avocado-12-967204.56.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 662168.5625 - val_loss: 967204.5625\n",
      "Epoch 13/1000\n",
      "346/400 [========================>.....] - ETA: 0s - loss: 477877.2812\n",
      "Epoch 00013: val_loss improved from 967204.56250 to 701440.25000, saving model to Models/avocado-13-701440.25.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 440338.7500 - val_loss: 701440.2500\n",
      "Epoch 14/1000\n",
      "333/400 [=======================>......] - ETA: 0s - loss: 263768.6875\n",
      "Epoch 00014: val_loss improved from 701440.25000 to 510967.21875, saving model to Models/avocado-14-510967.22.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 291191.3750 - val_loss: 510967.2188\n",
      "Epoch 15/1000\n",
      "336/400 [========================>.....] - ETA: 0s - loss: 205293.5938\n",
      "Epoch 00015: val_loss improved from 510967.21875 to 374532.96875, saving model to Models/avocado-15-374532.97.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 191908.4062 - val_loss: 374532.9688\n",
      "Epoch 16/1000\n",
      "392/400 [============================>.] - ETA: 0s - loss: 130186.2422\n",
      "Epoch 00016: val_loss improved from 374532.96875 to 275529.90625, saving model to Models/avocado-16-275529.91.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 128464.4766 - val_loss: 275529.9062\n",
      "Epoch 17/1000\n",
      "336/400 [========================>.....] - ETA: 0s - loss: 98503.6641 \n",
      "Epoch 00017: val_loss improved from 275529.90625 to 205140.62500, saving model to Models/avocado-17-205140.62.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 88272.8672 - val_loss: 205140.6250\n",
      "Epoch 18/1000\n",
      "332/400 [=======================>......] - ETA: 0s - loss: 67367.2500\n",
      "Epoch 00018: val_loss improved from 205140.62500 to 151867.95312, saving model to Models/avocado-18-151867.95.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 62635.6484 - val_loss: 151867.9531\n",
      "Epoch 19/1000\n",
      "334/400 [========================>.....] - ETA: 0s - loss: 46157.1758\n",
      "Epoch 00019: val_loss improved from 151867.95312 to 110021.44531, saving model to Models/avocado-19-110021.45.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 44493.0469 - val_loss: 110021.4453\n",
      "Epoch 20/1000\n",
      "349/400 [=========================>....] - ETA: 0s - loss: 29525.0781\n",
      "Epoch 00020: val_loss improved from 110021.44531 to 79469.56250, saving model to Models/avocado-20-79469.56.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 31288.7949 - val_loss: 79469.5625\n",
      "Epoch 21/1000\n",
      "329/400 [=======================>......] - ETA: 0s - loss: 22621.0254\n",
      "Epoch 00021: val_loss improved from 79469.56250 to 55755.00391, saving model to Models/avocado-21-55755.00.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 21985.4199 - val_loss: 55755.0039\n",
      "Epoch 22/1000\n",
      "344/400 [========================>.....] - ETA: 0s - loss: 15422.3604\n",
      "Epoch 00022: val_loss improved from 55755.00391 to 39043.26562, saving model to Models/avocado-22-39043.27.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 15507.0420 - val_loss: 39043.2656\n",
      "Epoch 23/1000\n",
      "345/400 [========================>.....] - ETA: 0s - loss: 11283.1221\n",
      "Epoch 00023: val_loss improved from 39043.26562 to 27877.20703, saving model to Models/avocado-23-27877.21.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 11274.5293 - val_loss: 27877.2070\n",
      "Epoch 24/1000\n",
      "391/400 [============================>.] - ETA: 0s - loss: 8475.9375\n",
      "Epoch 00024: val_loss improved from 27877.20703 to 19226.20703, saving model to Models/avocado-24-19226.21.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 8337.2119 - val_loss: 19226.2070\n",
      "Epoch 25/1000\n",
      "342/400 [========================>.....] - ETA: 0s - loss: 6541.6201\n",
      "Epoch 00025: val_loss improved from 19226.20703 to 13372.23145, saving model to Models/avocado-25-13372.23.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 6245.4634 - val_loss: 13372.2314\n",
      "Epoch 26/1000\n",
      "398/400 [============================>.] - ETA: 0s - loss: 4794.2627\n",
      "Epoch 00026: val_loss improved from 13372.23145 to 9107.66797, saving model to Models/avocado-26-9107.67.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 4780.0029 - val_loss: 9107.6680\n",
      "Epoch 27/1000\n",
      "333/400 [=======================>......] - ETA: 0s - loss: 4083.1963\n",
      "Epoch 00027: val_loss improved from 9107.66797 to 6309.89062, saving model to Models/avocado-27-6309.89.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 3715.7695 - val_loss: 6309.8906\n",
      "Epoch 28/1000\n",
      "382/400 [===========================>..] - ETA: 0s - loss: 3019.1133\n",
      "Epoch 00028: val_loss improved from 6309.89062 to 4511.00195, saving model to Models/avocado-28-4511.00.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 2948.7988 - val_loss: 4511.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000\n",
      "336/400 [========================>.....] - ETA: 0s - loss: 2609.7283\n",
      "Epoch 00029: val_loss improved from 4511.00195 to 3330.49414, saving model to Models/avocado-29-3330.49.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 2376.5859 - val_loss: 3330.4941\n",
      "Epoch 30/1000\n",
      "374/400 [===========================>..] - ETA: 0s - loss: 2016.9131\n",
      "Epoch 00030: val_loss improved from 3330.49414 to 2368.42310, saving model to Models/avocado-30-2368.42.hdf5\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 1911.7429 - val_loss: 2368.4231\n",
      "Epoch 31/1000\n",
      "347/400 [=========================>....] - ETA: 0s - loss: 1382.9622\n",
      "Epoch 00031: val_loss improved from 2368.42310 to 1560.13538, saving model to Models/avocado-31-1560.14.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1486.0372 - val_loss: 1560.1354\n",
      "Epoch 32/1000\n",
      "354/400 [=========================>....] - ETA: 0s - loss: 1155.7751\n",
      "Epoch 00032: val_loss improved from 1560.13538 to 961.78766, saving model to Models/avocado-32-961.79.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1094.4481 - val_loss: 961.7877\n",
      "Epoch 33/1000\n",
      "354/400 [=========================>....] - ETA: 0s - loss: 808.1705\n",
      "Epoch 00033: val_loss improved from 961.78766 to 629.74969, saving model to Models/avocado-33-629.75.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 790.4955 - val_loss: 629.7497\n",
      "Epoch 34/1000\n",
      "354/400 [=========================>....] - ETA: 0s - loss: 567.6766\n",
      "Epoch 00034: val_loss improved from 629.74969 to 428.43414, saving model to Models/avocado-34-428.43.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 551.7721 - val_loss: 428.4341\n",
      "Epoch 35/1000\n",
      "336/400 [========================>.....] - ETA: 0s - loss: 413.2136\n",
      "Epoch 00035: val_loss improved from 428.43414 to 282.50946, saving model to Models/avocado-35-282.51.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 377.4488 - val_loss: 282.5095\n",
      "Epoch 36/1000\n",
      "388/400 [============================>.] - ETA: 0s - loss: 251.1115\n",
      "Epoch 00036: val_loss improved from 282.50946 to 185.54208, saving model to Models/avocado-36-185.54.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 252.9877 - val_loss: 185.5421\n",
      "Epoch 37/1000\n",
      "351/400 [=========================>....] - ETA: 0s - loss: 166.6001\n",
      "Epoch 00037: val_loss improved from 185.54208 to 124.02901, saving model to Models/avocado-37-124.03.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 170.5916 - val_loss: 124.0290\n",
      "Epoch 38/1000\n",
      "337/400 [========================>.....] - ETA: 0s - loss: 133.7390\n",
      "Epoch 00038: val_loss improved from 124.02901 to 83.00867, saving model to Models/avocado-38-83.01.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 117.2775 - val_loss: 83.0087\n",
      "Epoch 39/1000\n",
      "347/400 [=========================>....] - ETA: 0s - loss: 93.4473\n",
      "Epoch 00039: val_loss improved from 83.00867 to 55.30167, saving model to Models/avocado-39-55.30.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 82.0120 - val_loss: 55.3017\n",
      "Epoch 40/1000\n",
      "354/400 [=========================>....] - ETA: 0s - loss: 52.8552\n",
      "Epoch 00040: val_loss improved from 55.30167 to 35.66161, saving model to Models/avocado-40-35.66.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 57.1913 - val_loss: 35.6616\n",
      "Epoch 41/1000\n",
      "339/400 [========================>.....] - ETA: 0s - loss: 44.7018\n",
      "Epoch 00041: val_loss improved from 35.66161 to 22.89777, saving model to Models/avocado-41-22.90.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 39.0174 - val_loss: 22.8978\n",
      "Epoch 42/1000\n",
      "351/400 [=========================>....] - ETA: 0s - loss: 27.9869\n",
      "Epoch 00042: val_loss improved from 22.89777 to 14.58799, saving model to Models/avocado-42-14.59.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 26.9477 - val_loss: 14.5880\n",
      "Epoch 43/1000\n",
      "340/400 [========================>.....] - ETA: 0s - loss: 21.3333\n",
      "Epoch 00043: val_loss improved from 14.58799 to 8.77637, saving model to Models/avocado-43-8.78.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 18.5802 - val_loss: 8.7764\n",
      "Epoch 44/1000\n",
      "357/400 [=========================>....] - ETA: 0s - loss: 9.7715 \n",
      "Epoch 00044: val_loss improved from 8.77637 to 5.19151, saving model to Models/avocado-44-5.19.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 12.4363 - val_loss: 5.1915\n",
      "Epoch 45/1000\n",
      "352/400 [=========================>....] - ETA: 0s - loss: 8.6196\n",
      "Epoch 00045: val_loss improved from 5.19151 to 2.69943, saving model to Models/avocado-45-2.70.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 8.2829 - val_loss: 2.6994\n",
      "Epoch 46/1000\n",
      "349/400 [=========================>....] - ETA: 0s - loss: 5.9925\n",
      "Epoch 00046: val_loss improved from 2.69943 to 1.48883, saving model to Models/avocado-46-1.49.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 5.6683 - val_loss: 1.4888\n",
      "Epoch 47/1000\n",
      "351/400 [=========================>....] - ETA: 0s - loss: 3.4409\n",
      "Epoch 00047: val_loss improved from 1.48883 to 0.76043, saving model to Models/avocado-47-0.76.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 4.0291 - val_loss: 0.7604\n",
      "Epoch 48/1000\n",
      "390/400 [============================>.] - ETA: 0s - loss: 2.7655\n",
      "Epoch 00048: val_loss improved from 0.76043 to 0.43243, saving model to Models/avocado-48-0.43.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 2.9662 - val_loss: 0.4324\n",
      "Epoch 49/1000\n",
      "351/400 [=========================>....] - ETA: 0s - loss: 2.2613\n",
      "Epoch 00049: val_loss improved from 0.43243 to 0.30857, saving model to Models/avocado-49-0.31.hdf5\n",
      "400/400 [==============================] - 0s 997us/step - loss: 2.3446 - val_loss: 0.3086\n",
      "Epoch 50/1000\n",
      "332/400 [=======================>......] - ETA: 0s - loss: 1.7677\n",
      "Epoch 00050: val_loss improved from 0.30857 to 0.25948, saving model to Models/avocado-50-0.26.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.8358 - val_loss: 0.2595\n",
      "Epoch 51/1000\n",
      "360/400 [==========================>...] - ETA: 0s - loss: 1.1738\n",
      "Epoch 00051: val_loss improved from 0.25948 to 0.21907, saving model to Models/avocado-51-0.22.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.3956 - val_loss: 0.2191\n",
      "Epoch 52/1000\n",
      "341/400 [========================>.....] - ETA: 0s - loss: 1.1978\n",
      "Epoch 00052: val_loss improved from 0.21907 to 0.19552, saving model to Models/avocado-52-0.20.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.0465 - val_loss: 0.1955\n",
      "Epoch 53/1000\n",
      "353/400 [=========================>....] - ETA: 0s - loss: 0.7874\n",
      "Epoch 00053: val_loss improved from 0.19552 to 0.17376, saving model to Models/avocado-53-0.17.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7152 - val_loss: 0.1738\n",
      "Epoch 54/1000\n",
      "336/400 [========================>.....] - ETA: 0s - loss: 0.5428\n",
      "Epoch 00054: val_loss improved from 0.17376 to 0.16937, saving model to Models/avocado-54-0.17.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.4819 - val_loss: 0.1694\n",
      "Epoch 55/1000\n",
      "337/400 [========================>.....] - ETA: 0s - loss: 0.2967\n",
      "Epoch 00055: val_loss improved from 0.16937 to 0.16841, saving model to Models/avocado-55-0.17.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.1684\n",
      "Epoch 56/1000\n",
      "351/400 [=========================>....] - ETA: 0s - loss: 0.2794\n",
      "Epoch 00056: val_loss improved from 0.16841 to 0.16743, saving model to Models/avocado-56-0.17.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2678 - val_loss: 0.1674\n",
      "Epoch 57/1000\n",
      "343/400 [========================>.....] - ETA: 0s - loss: 0.1947\n",
      "Epoch 00057: val_loss improved from 0.16743 to 0.16738, saving model to Models/avocado-57-0.17.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2106 - val_loss: 0.1674\n",
      "Epoch 58/1000\n",
      "357/400 [=========================>....] - ETA: 0s - loss: 0.1757\n",
      "Epoch 00058: val_loss did not improve from 0.16738\n",
      "400/400 [==============================] - 0s 961us/step - loss: 0.1909 - val_loss: 0.1674\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/400 [========================>.....] - ETA: 0s - loss: 0.1808\n",
      "Epoch 00059: val_loss did not improve from 0.16738\n",
      "400/400 [==============================] - 0s 991us/step - loss: 0.1782 - val_loss: 0.1675\n",
      "Epoch 60/1000\n",
      "393/400 [============================>.] - ETA: 0s - loss: 0.1704\n",
      "Epoch 00060: val_loss did not improve from 0.16738\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.1703 - val_loss: 0.1676\n",
      "Epoch 61/1000\n",
      "346/400 [========================>.....] - ETA: 0s - loss: 0.1700\n",
      "Epoch 00061: val_loss did not improve from 0.16738\n",
      "400/400 [==============================] - 0s 983us/step - loss: 0.1681 - val_loss: 0.1676\n",
      "Epoch 62/1000\n",
      "345/400 [========================>.....] - ETA: 0s - loss: 0.1623\n",
      "Epoch 00062: val_loss did not improve from 0.16738\n",
      "400/400 [==============================] - 0s 986us/step - loss: 0.1650 - val_loss: 0.1676\n",
      "Epoch 63/1000\n",
      "353/400 [=========================>....] - ETA: 0s - loss: 0.1606\n",
      "Epoch 00063: val_loss did not improve from 0.16738\n",
      "400/400 [==============================] - 0s 962us/step - loss: 0.1633 - val_loss: 0.1676\n",
      "Epoch 64/1000\n",
      "357/400 [=========================>....] - ETA: 0s - loss: 0.1610\n",
      "Epoch 00064: val_loss did not improve from 0.16738\n",
      "400/400 [==============================] - 0s 984us/step - loss: 0.1621 - val_loss: 0.1675\n",
      "Epoch 65/1000\n",
      "392/400 [============================>.] - ETA: 0s - loss: 0.1616\n",
      "Epoch 00065: val_loss did not improve from 0.16738\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.1620 - val_loss: 0.1676\n",
      "Epoch 66/1000\n",
      "358/400 [=========================>....] - ETA: 0s - loss: 0.1629\n",
      "Epoch 00066: val_loss did not improve from 0.16738\n",
      "400/400 [==============================] - 0s 962us/step - loss: 0.1619 - val_loss: 0.1674\n",
      "Epoch 67/1000\n",
      "342/400 [========================>.....] - ETA: 0s - loss: 0.1617\n",
      "Epoch 00067: val_loss did not improve from 0.16738\n",
      "400/400 [==============================] - 0s 980us/step - loss: 0.1619 - val_loss: 0.1675\n",
      "Epoch 68/1000\n",
      "366/400 [==========================>...] - ETA: 0s - loss: 0.1622\n",
      "Epoch 00068: val_loss did not improve from 0.16738\n",
      "400/400 [==============================] - 0s 941us/step - loss: 0.1619 - val_loss: 0.1674\n",
      "Epoch 69/1000\n",
      "352/400 [=========================>....] - ETA: 0s - loss: 0.1622\n",
      "Epoch 00069: val_loss improved from 0.16738 to 0.16731, saving model to Models/avocado-69-0.17.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.1618 - val_loss: 0.1673\n",
      "Epoch 70/1000\n",
      "339/400 [========================>.....] - ETA: 0s - loss: 0.1604\n",
      "Epoch 00070: val_loss improved from 0.16731 to 0.16730, saving model to Models/avocado-70-0.17.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.1618 - val_loss: 0.1673\n",
      "Epoch 71/1000\n",
      "355/400 [=========================>....] - ETA: 0s - loss: 0.1617\n",
      "Epoch 00071: val_loss did not improve from 0.16730\n",
      "400/400 [==============================] - 0s 965us/step - loss: 0.1618 - val_loss: 0.1676\n",
      "Epoch 72/1000\n",
      "348/400 [=========================>....] - ETA: 0s - loss: 0.1614\n",
      "Epoch 00072: val_loss did not improve from 0.16730\n",
      "400/400 [==============================] - 0s 983us/step - loss: 0.1618 - val_loss: 0.1675\n",
      "Epoch 73/1000\n",
      "336/400 [========================>.....] - ETA: 0s - loss: 0.1613\n",
      "Epoch 00073: val_loss improved from 0.16730 to 0.16729, saving model to Models/avocado-73-0.17.hdf5\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.1618 - val_loss: 0.1673\n",
      "Epoch 74/1000\n",
      "343/400 [========================>.....] - ETA: 0s - loss: 0.1616\n",
      "Epoch 00074: val_loss did not improve from 0.16729\n",
      "400/400 [==============================] - 0s 996us/step - loss: 0.1618 - val_loss: 0.1676\n",
      "Epoch 75/1000\n",
      "352/400 [=========================>....] - ETA: 0s - loss: 0.1631\n",
      "Epoch 00075: val_loss did not improve from 0.16729\n",
      "400/400 [==============================] - 0s 960us/step - loss: 0.1618 - val_loss: 0.1674\n",
      "Epoch 76/1000\n",
      "360/400 [==========================>...] - ETA: 0s - loss: 0.1617\n",
      "Epoch 00076: val_loss did not improve from 0.16729\n",
      "400/400 [==============================] - 0s 953us/step - loss: 0.1618 - val_loss: 0.1674\n",
      "Epoch 77/1000\n",
      "352/400 [=========================>....] - ETA: 0s - loss: 0.1618\n",
      "Epoch 00077: val_loss did not improve from 0.16729\n",
      "400/400 [==============================] - 0s 971us/step - loss: 0.1618 - val_loss: 0.1674\n",
      "Epoch 78/1000\n",
      "345/400 [========================>.....] - ETA: 0s - loss: 0.1619\n",
      "Epoch 00078: val_loss did not improve from 0.16729\n",
      "400/400 [==============================] - 0s 976us/step - loss: 0.1618 - val_loss: 0.1673\n",
      "Epoch 79/1000\n",
      "358/400 [=========================>....] - ETA: 0s - loss: 0.1621\n",
      "Epoch 00079: val_loss improved from 0.16729 to 0.16726, saving model to Models/avocado-79-0.17.hdf5\n",
      "400/400 [==============================] - 0s 990us/step - loss: 0.1618 - val_loss: 0.1673\n",
      "Epoch 80/1000\n",
      "333/400 [=======================>......] - ETA: 0s - loss: 0.1606\n",
      "Epoch 00080: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 999us/step - loss: 0.1618 - val_loss: 0.1673\n",
      "Epoch 81/1000\n",
      "357/400 [=========================>....] - ETA: 0s - loss: 0.1610\n",
      "Epoch 00081: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 956us/step - loss: 0.1618 - val_loss: 0.1673\n",
      "Epoch 82/1000\n",
      "354/400 [=========================>....] - ETA: 0s - loss: 0.1619\n",
      "Epoch 00082: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 964us/step - loss: 0.1618 - val_loss: 0.1675\n",
      "Epoch 83/1000\n",
      "343/400 [========================>.....] - ETA: 0s - loss: 0.1608\n",
      "Epoch 00083: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 974us/step - loss: 0.1617 - val_loss: 0.1678\n",
      "Epoch 84/1000\n",
      "360/400 [==========================>...] - ETA: 0s - loss: 0.1616\n",
      "Epoch 00084: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 956us/step - loss: 0.1618 - val_loss: 0.1675\n",
      "Epoch 85/1000\n",
      "386/400 [===========================>..] - ETA: 0s - loss: 0.1613\n",
      "Epoch 00085: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.1618 - val_loss: 0.1675\n",
      "Epoch 86/1000\n",
      "343/400 [========================>.....] - ETA: 0s - loss: 0.1631\n",
      "Epoch 00086: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.1618 - val_loss: 0.1675\n",
      "Epoch 87/1000\n",
      "331/400 [=======================>......] - ETA: 0s - loss: 0.1606\n",
      "Epoch 00087: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.1618 - val_loss: 0.1674\n",
      "Epoch 88/1000\n",
      "364/400 [==========================>...] - ETA: 0s - loss: 0.1618\n",
      "Epoch 00088: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 942us/step - loss: 0.1618 - val_loss: 0.1674\n",
      "Epoch 89/1000\n",
      "358/400 [=========================>....] - ETA: 0s - loss: 0.1622\n",
      "Epoch 00089: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 961us/step - loss: 0.1618 - val_loss: 0.1673\n",
      "Epoch 90/1000\n",
      "353/400 [=========================>....] - ETA: 0s - loss: 0.1622\n",
      "Epoch 00090: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 981us/step - loss: 0.1618 - val_loss: 0.1675\n",
      "Epoch 91/1000\n",
      "341/400 [========================>.....] - ETA: 0s - loss: 0.1612\n",
      "Epoch 00091: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 982us/step - loss: 0.1618 - val_loss: 0.1673\n",
      "Epoch 92/1000\n",
      "362/400 [==========================>...] - ETA: 0s - loss: 0.1623\n",
      "Epoch 00092: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 955us/step - loss: 0.1618 - val_loss: 0.1675\n",
      "Epoch 93/1000\n",
      "352/400 [=========================>....] - ETA: 0s - loss: 0.1621\n",
      "Epoch 00093: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 971us/step - loss: 0.1618 - val_loss: 0.1674\n",
      "Epoch 94/1000\n",
      "356/400 [=========================>....] - ETA: 0s - loss: 0.1606\n",
      "Epoch 00094: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 957us/step - loss: 0.1618 - val_loss: 0.1675\n",
      "Epoch 95/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/400 [==========================>...] - ETA: 0s - loss: 0.1608\n",
      "Epoch 00095: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 947us/step - loss: 0.1618 - val_loss: 0.1673\n",
      "Epoch 96/1000\n",
      "351/400 [=========================>....] - ETA: 0s - loss: 0.1609\n",
      "Epoch 00096: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 966us/step - loss: 0.1618 - val_loss: 0.1674\n",
      "Epoch 97/1000\n",
      "347/400 [=========================>....] - ETA: 0s - loss: 0.1618\n",
      "Epoch 00097: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 973us/step - loss: 0.1618 - val_loss: 0.1673\n",
      "Epoch 98/1000\n",
      "355/400 [=========================>....] - ETA: 0s - loss: 0.1610\n",
      "Epoch 00098: val_loss did not improve from 0.16726\n",
      "400/400 [==============================] - 0s 955us/step - loss: 0.1618 - val_loss: 0.1674\n",
      "Epoch 00098: early stopping\n",
      "172/172 [==============================] - 0s 572us/step - loss: 0.1674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1674385964870453"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=32, callbacks=callbacks)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 572us/step - loss: 0.1674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1674385964870453"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 49: Predicting Avocado Price Using Entity Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18249 entries, 0 to 18248\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    18249 non-null  int64  \n",
      " 1   Date          18249 non-null  object \n",
      " 2   AveragePrice  18249 non-null  float64\n",
      " 3   Total Volume  18249 non-null  float64\n",
      " 4   4046          18249 non-null  float64\n",
      " 5   4225          18249 non-null  float64\n",
      " 6   4770          18249 non-null  float64\n",
      " 7   Total Bags    18249 non-null  float64\n",
      " 8   Small Bags    18249 non-null  float64\n",
      " 9   Large Bags    18249 non-null  float64\n",
      " 10  XLarge Bags   18249 non-null  float64\n",
      " 11  type          18249 non-null  object \n",
      " 12  year          18249 non-null  int64  \n",
      " 13  region        18249 non-null  object \n",
      "dtypes: float64(9), int64(2), object(3)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "data = pd.read_csv('data/avocado.csv')\n",
    "data.info()\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data column into days and months\n",
    "data['Day'], data['Month'] = data.Date.str[:2], data.Date.str[3:5]\n",
    "#drop date and unnamed\n",
    "data = data.drop(['Unnamed: 0', 'Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use LabelEncoder for categorical variables \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from collections import defaultdict \n",
    "\n",
    "#Create label dictionary \n",
    "label_dict = defaultdict(LabelEncoder)\n",
    "\n",
    "data[['region', 'type', 'Day', 'Month', 'year']] = data[['region', 'type', 'Day', 'Month', 'year']]\\\n",
    "                                                   .apply(lambda x: label_dict[x.name].fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data \n",
    "y = X.pop('AveragePrice')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary that maps categorical column names to the unique values in them \n",
    "cat_cols_dict = {col: list(data[col].unique()) for col in ['region', 'type', 'Day', 'Month', 'year']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([53, 21,  2, ..., 42, 16,  9]),\n",
       " array([0, 1, 1, ..., 0, 1, 0]),\n",
       " array([ 7, 16, 24, ..., 23,  1,  9]),\n",
       " array([4, 3, 1, ..., 6, 7, 4]),\n",
       " array([1, 1, 3, ..., 1, 0, 0]),\n",
       " array([[1.05294048e+06, 6.23286740e+05, 1.83588620e+05, ...,\n",
       "         1.24984250e+05, 8.35601900e+04, 4.29667000e+03],\n",
       "        [2.00015400e+04, 2.83014000e+03, 1.35565700e+04, ...,\n",
       "         3.47320000e+02, 3.26751000e+03, 0.00000000e+00],\n",
       "        [4.74211500e+04, 1.62630000e+03, 7.91327000e+03, ...,\n",
       "         3.78221300e+04, 1.00000000e+01, 0.00000000e+00],\n",
       "        ...,\n",
       "        [8.17357280e+05, 1.58290860e+05, 5.27450530e+05, ...,\n",
       "         7.28537700e+04, 1.01394000e+03, 1.39861000e+03],\n",
       "        [2.72836000e+03, 6.96300000e+01, 1.98740000e+02, ...,\n",
       "         2.44855000e+03, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.59598760e+05, 1.19823900e+04, 1.72173770e+05, ...,\n",
       "         2.25069200e+04, 5.02650400e+04, 2.62550000e+02]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the input data in the format the embedding neural network will accept \n",
    "train_input_list = []\n",
    "test_input_list = []\n",
    "\n",
    "for col in cat_cols_dict.keys():\n",
    "    raw_values = np.unique(data[col])\n",
    "    value_map = {}\n",
    "    for i in range(len(raw_values)):\n",
    "        value_map[raw_values[i]] = i\n",
    "    train_input_list.append(X_train[col].map(value_map).values)\n",
    "    test_input_list.append(X_test[col].map(value_map).fillna(0).values)\n",
    "\n",
    "other_cols = [col for col in data.columns if (not col in cat_cols_dict.keys())]\n",
    "train_input_list.append(X_train[other_cols].values)\n",
    "test_input_list.append(X_test[other_cols].values)\n",
    "\n",
    "train_input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_out_dict = {'region':12, \n",
    "                 'type': 1,\n",
    "                 'Day': 10,\n",
    "                 'Month': 3,\n",
    "                 'year': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we create the embedding layers for the categorical variables \n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate, Reshape, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "inputs = []\n",
    "embeddings = []\n",
    "\n",
    "for col in cat_cols_dict.keys():\n",
    "    inp = Input(shape=(1,), name = f'input_{col}')\n",
    "    embedding = Embedding(len(cat_cols_dict[col]), cols_out_dict[col], input_length=1, name=f'embedding_{col}')(inp)\n",
    "    embedding = Reshape(target_shape=(cols_out_dict[col],))(embedding)\n",
    "    inputs.append(inp)\n",
    "    embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_region (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_type (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_Day (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_Month (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_year (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_region (Embedding)    (None, 1, 12)        648         input_region[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_type (Embedding)      (None, 1, 1)         2           input_type[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_Day (Embedding)       (None, 1, 10)        310         input_Day[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_Month (Embedding)     (None, 1, 3)         36          input_Month[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_year (Embedding)      (None, 1, 1)         4           input_year[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 12)           0           embedding_region[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           embedding_type[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10)           0           embedding_Day[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 3)            0           embedding_Month[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1)            0           embedding_year[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           144         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 43)           0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           704         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            68          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            5           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,921\n",
      "Trainable params: 1,921\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_numeric = Input(shape=(8, ))\n",
    "embedding_numeric = Dense(16)(input_numeric)\n",
    "inputs.append(input_numeric)\n",
    "embeddings.append(embedding_numeric)\n",
    "\n",
    "x = Concatenate()(embeddings)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = Dense(4, activation='relu')(x)\n",
    "output = Dense(1, activation='linear')(x)\n",
    "\n",
    "model = Model(inputs, output)\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 298655842304.0000 - val_loss: 579930176.0000\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 491214112.0000 - val_loss: 437478368.0000\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 320238976.0000 - val_loss: 222775760.0000\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 215002448.0000 - val_loss: 145548320.0000\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 181297216.0000 - val_loss: 107870744.0000\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 143366560.0000 - val_loss: 108308232.0000\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 73185568.0000 - val_loss: 48038888.0000\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 56736324.0000 - val_loss: 41787180.0000\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 52071036.0000 - val_loss: 22365468.0000\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 23878022.0000 - val_loss: 37515192.0000\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 56309092.0000 - val_loss: 228679680.0000\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 733400256.0000 - val_loss: 7852.9702\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 11130.4863 - val_loss: 7559.1636\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 8438.7412 - val_loss: 7777.9873\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 7434.8228 - val_loss: 8006.9233\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 6863.8955 - val_loss: 8110.2778\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 6596.6025 - val_loss: 8107.7749\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 6402.7383 - val_loss: 8050.8706\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 6204.3354 - val_loss: 7858.3892\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 6025.7197 - val_loss: 7630.0776\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 5818.8452 - val_loss: 7404.7832\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 5561.6445 - val_loss: 7020.3872\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 5272.4009 - val_loss: 6615.6147\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 4956.6733 - val_loss: 6188.7876\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 4605.3179 - val_loss: 5672.2671\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 4230.1436 - val_loss: 5058.9878\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 3850.0391 - val_loss: 4528.5562\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 3460.1599 - val_loss: 4064.5056\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 3034.5105 - val_loss: 3785.2964\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 2628.3176 - val_loss: 3257.4922\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 2214.1331 - val_loss: 2823.3152\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 1796.9625 - val_loss: 2294.7764\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 1458.2040 - val_loss: 2098.1721\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 1138.4316 - val_loss: 1610.0493\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 890.6583 - val_loss: 1366.8152\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 678.9606 - val_loss: 1067.8051\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 515.9699 - val_loss: 789.1385\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 381.6171 - val_loss: 561.7906\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 286.3424 - val_loss: 400.6657\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 211.5271 - val_loss: 274.6928\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 157.2702 - val_loss: 185.7838\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 119.0561 - val_loss: 127.9330\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 89.5996 - val_loss: 85.2153\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 68.4141 - val_loss: 55.1603\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 50.3771 - val_loss: 36.4931\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 37.6205 - val_loss: 26.4057\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 28.1693 - val_loss: 19.5363\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 19.6465 - val_loss: 13.2864\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 14.8729 - val_loss: 9.9993\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 10.9355 - val_loss: 7.2908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1403fa520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_input_list, y_train, validation_data = (test_input_list, y_test), epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_region = model.get_layer('embedding_region').get_weights()[0]\n",
    "\n",
    "label_dict['region'].inverse_transform(cat_cols_dict['region'])\n",
    "\n",
    "#Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "Y = pca.fit_transform(embedding_region[:25])\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(-Y[:, 0], -Y[:, 1])\n",
    "for i, txt in enumerate((label_dict['region'].inverse_transform(cat_cols_dict['region']))[:25]):\n",
    "    plt.annotate(txt, (-Y[i, 0],-Y[i, 1]), xytext = (-20, 8), textcoords = 'offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('Models/avocado-32-0.17.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 598us/step - loss: 0.1716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17164941132068634"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 369\n",
      "Trainable params: 369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 369\n",
      "Trainable params: 369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScienceTensorflow",
   "language": "python",
   "name": "datasciencetensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
